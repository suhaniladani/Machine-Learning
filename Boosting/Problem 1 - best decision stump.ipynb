{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5 \n",
    "\n",
    "dataset = pd.read_csv(\"../spambase/spambase.data\", header=None) \n",
    "dataset = np.array(dataset)\n",
    "for instance in dataset:\n",
    "    if instance[-1] == 1:\n",
    "        instance[-1] = 1\n",
    "    else:\n",
    "        instance[-1] = -1\n",
    "return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_k_folds(dataset, k):\n",
    "\n",
    "    np.random.shuffle(dataset)\n",
    "    dataset = np.array_split(dataset, k)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def separate_attributes(dataset):\n",
    "#     Separate inputs from outputs and return a dictionary.\n",
    "    \n",
    "#     Now it is possible to convert outputs to true integers. \n",
    "    \n",
    "#     Arguments: dataset -- Dataset represented as numpy array of arrays.\n",
    "\n",
    "\n",
    "    dataset = {\n",
    "        \"input\": dataset[:, 0:-1],\n",
    "        \"output\": dataset[:, -1].astype(int)\n",
    "    }\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def __init__(training_set, testing_set):\n",
    "\n",
    "    training_set = training_set\n",
    "    testing_set = testing_set\n",
    "\n",
    "    m_tr = training_set[\"input\"].shape[0] \n",
    "\n",
    "    n_tr = training_set[\"input\"].shape[1]  \n",
    "\n",
    "    m_ts = testing_set[\"input\"].shape[0]\n",
    "\n",
    "    weights = np.divide(np.ones(m_tr), m_tr)  \n",
    "\n",
    "    ensemble = [] \n",
    "\n",
    "    alpha = []  \n",
    "\n",
    "\n",
    "def evaluate_stump(self, stump):\n",
    "\n",
    "    predictions = np.zeros(m_tr)  \n",
    "    pred_errors = np.ones(m_tr) \n",
    "    a = stump[\"attribute\"]  \n",
    "    # Loop through instances\n",
    "    for i in range(m_tr):\n",
    "        value = training_set[\"input\"][i][a]\n",
    "        output = training_set[\"output\"][i]\n",
    "        if value == stump[\"value\"]:\n",
    "            predictions[i] = stump[\"state\"]\n",
    "        else:\n",
    "            predictions[i] = stump[\"state\"] * -1\n",
    "        if predictions[i] == output:\n",
    "            pred_errors[i] = 0\n",
    "\n",
    "\n",
    "    error = np.sum(np.multiply(weights, pred_errors))\n",
    "\n",
    "    return error, predictions\n",
    "\n",
    "\n",
    "def find_best_stump(self):\n",
    "    best_stump = {}\n",
    "    lowest_error = float(\"inf\")\n",
    "    possible_states = [1, -1]\n",
    "    for a in range(n_tr):\n",
    "        feature_values = np.expand_dims(training_set[\"input\"][a], axis=1)\n",
    "        possible_values = np.unique(feature_values)\n",
    "        for value in possible_values:\n",
    "            for state in possible_states:\n",
    "                stump = {\"attribute\": a}\n",
    "                stump[\"value\"] = value\n",
    "                stump[\"state\"] = state  \n",
    "                error, predictions = evaluate_stump(stump)\n",
    "                stump[\"error\"] = error\n",
    "                stump[\"predictions\"] = predictions\n",
    "\n",
    "                if error < lowest_error:\n",
    "                    lowest_error = error\n",
    "                    best_stump = stump\n",
    "\n",
    "    return best_stump\n",
    "\n",
    "\n",
    "def calculate_alpha(self, model):\n",
    "\n",
    "    error = model[\"error\"]\n",
    "    alpha = 0.5 * np.log((1 - error) / error)\n",
    "\n",
    "    return alpha\n",
    "\n",
    "\n",
    "def update_weights(self, model, alpha):\n",
    "\n",
    "\n",
    "    weights = np.multiply(weights, \n",
    "                               np.exp(-1 * alpha \n",
    "                                 * np.multiply(training_set[\"output\"],\n",
    "                                               model[\"predictions\"])\n",
    "                               )\n",
    "                   )\n",
    "\n",
    "    weights = np.divide(weights, np.sum(weights))\n",
    "\n",
    "\n",
    "def evaluate_ensemble(self):\n",
    "\n",
    "    correct = 0\n",
    "    for i in range(m_ts):\n",
    "        H = 0  \n",
    "        for model in range(len(ensemble)):\n",
    "\n",
    "            a = ensemble[model][\"attribute\"]\n",
    "\n",
    "            value = testing_set[\"input\"][i][a]\n",
    "\n",
    "            if value == ensemble[model][\"value\"]:\n",
    "                prediction = ensemble[model][\"state\"]\n",
    "            else:\n",
    "                prediction = ensemble[model][\"state\"] * -1\n",
    "            H += alpha[model] * prediction\n",
    "        H = np.sign(H)  \n",
    "\n",
    "        if H == testing_set[\"output\"][i]:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = (correct / m_ts) * 100  \n",
    "    error = 100 - accuracy\n",
    "\n",
    "    return accuracy, error\n",
    "\n",
    "\n",
    "def boost(self, num_iterations):\n",
    "\n",
    "    accuracies = []  \n",
    "    errors = [] \n",
    "    model_errors = []  \n",
    "    for i in range(num_iterations):\n",
    "        print(i)\n",
    "        best_model = find_best_stump()\n",
    "        model_errors.append(best_model[\"error\"] * 100)\n",
    "        ensemble.append(best_model)\n",
    "        alpha.append(calculate_alpha(best_model)) \n",
    "\n",
    "        results = evaluate_ensemble()\n",
    "        accuracies.append(results[0])\n",
    "        errors.append(results[1])\n",
    "\n",
    "        update_weights(best_model, alpha[i])\n",
    "    return accuracies, errors, model_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_accuracies = []\n",
    "cv_errors = []\n",
    "cv_model_errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = make_k_folds(dataset, k)\n",
    "\n",
    "\n",
    "for i in range(k):\n",
    "    testing_set = separate_attributes(dataset[i])\n",
    "    remaining_folds = np.concatenate(np.delete(dataset, i))\n",
    "    training_set = separate_attributes(remaining_folds)\n",
    "\n",
    "    ada = AdaBoost(training_set, testing_set)\n",
    "    results = ada.boost(100)\n",
    "\n",
    "    cv_accuracies.append(results[0])\n",
    "    cv_errors.append(results[1])\n",
    "    cv_model_errors.append(results[2])\n",
    "\n",
    "cv_accuracies = np.asarray(cv_accuracies)\n",
    "cv_errors = np.asarray(cv_errors)\n",
    "cv_model_errors = np.asarray(cv_model_errors)\n",
    "\n",
    "cv_accuracies = np.divide(np.sum(cv_accuracies, axis=0), k)\n",
    "cv_errors = np.divide(np.sum(cv_errors, axis=0), k)\n",
    "cv_model_errors = np.divide(np.sum(cv_model_errors, axis=0), k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.32770251119551"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_accuracies[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
