{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = pd.read_csv(\"spam_polluted/train_feature.txt\", delim_whitespace=True, header=None) \n",
    "test_feature = pd.read_csv(\"spam_polluted/test_feature.txt\", delim_whitespace=True, header=None) \n",
    "train_label = pd.read_csv(\"spam_polluted/train_label.txt\", delim_whitespace=True, header=None) \n",
    "test_label = pd.read_csv(\"spam_polluted/test_label.txt\", delim_whitespace=True, header=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WholeDf = pd.concat([train_feature, test_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1047</th>\n",
       "      <th>1048</th>\n",
       "      <th>1049</th>\n",
       "      <th>1050</th>\n",
       "      <th>1051</th>\n",
       "      <th>1052</th>\n",
       "      <th>1053</th>\n",
       "      <th>1054</th>\n",
       "      <th>1055</th>\n",
       "      <th>1056</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041051</td>\n",
       "      <td>0.068515</td>\n",
       "      <td>0.014376</td>\n",
       "      <td>0.068351</td>\n",
       "      <td>0.032469</td>\n",
       "      <td>0.014087</td>\n",
       "      <td>0.034152</td>\n",
       "      <td>0.051189</td>\n",
       "      <td>0.063388</td>\n",
       "      <td>0.043658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062413</td>\n",
       "      <td>0.050598</td>\n",
       "      <td>0.071449</td>\n",
       "      <td>0.034827</td>\n",
       "      <td>0.037157</td>\n",
       "      <td>0.051147</td>\n",
       "      <td>0.067859</td>\n",
       "      <td>0.052220</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.009583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019171</td>\n",
       "      <td>0.045824</td>\n",
       "      <td>0.011757</td>\n",
       "      <td>0.031530</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>0.073789</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>0.072750</td>\n",
       "      <td>0.040348</td>\n",
       "      <td>0.029986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010594</td>\n",
       "      <td>0.013711</td>\n",
       "      <td>0.054859</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>0.053976</td>\n",
       "      <td>0.029885</td>\n",
       "      <td>0.063413</td>\n",
       "      <td>0.070903</td>\n",
       "      <td>0.026120</td>\n",
       "      <td>0.008427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055207</td>\n",
       "      <td>0.071441</td>\n",
       "      <td>0.058734</td>\n",
       "      <td>0.058241</td>\n",
       "      <td>0.034914</td>\n",
       "      <td>0.018111</td>\n",
       "      <td>0.019574</td>\n",
       "      <td>0.009803</td>\n",
       "      <td>0.065727</td>\n",
       "      <td>0.058667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1057 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9       ...     \\\n",
       "0  0.21  0.28  0.50   0.0  0.14  0.28  0.21  0.07  0.00  0.94    ...      \n",
       "1  0.06  0.00  0.71   0.0  1.23  0.19  0.19  0.12  0.64  0.25    ...      \n",
       "2  0.00  0.00  0.00   0.0  0.63  0.00  0.31  0.63  0.31  0.63    ...      \n",
       "3  0.00  0.00  0.00   0.0  0.63  0.00  0.31  0.63  0.31  0.63    ...      \n",
       "4  0.00  0.00  0.00   0.0  1.85  0.00  0.00  1.85  0.00  0.00    ...      \n",
       "\n",
       "       1047      1048      1049      1050      1051      1052      1053  \\\n",
       "0  0.041051  0.068515  0.014376  0.068351  0.032469  0.014087  0.034152   \n",
       "1  0.062413  0.050598  0.071449  0.034827  0.037157  0.051147  0.067859   \n",
       "2  0.019171  0.045824  0.011757  0.031530  0.032750  0.073789  0.045900   \n",
       "3  0.010594  0.013711  0.054859  0.004493  0.053976  0.029885  0.063413   \n",
       "4  0.055207  0.071441  0.058734  0.058241  0.034914  0.018111  0.019574   \n",
       "\n",
       "       1054      1055      1056  \n",
       "0  0.051189  0.063388  0.043658  \n",
       "1  0.052220  0.004742  0.009583  \n",
       "2  0.072750  0.040348  0.029986  \n",
       "3  0.070903  0.026120  0.008427  \n",
       "4  0.009803  0.065727  0.058667  \n",
       "\n",
       "[5 rows x 1057 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WholeDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalComponents = pca.fit_transform(WholeDf)\n",
    "principalDf = pd.DataFrame(data = principalComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>742.633046</td>\n",
       "      <td>-74.001388</td>\n",
       "      <td>-0.568021</td>\n",
       "      <td>-1.238880</td>\n",
       "      <td>0.584801</td>\n",
       "      <td>-0.142957</td>\n",
       "      <td>-0.203460</td>\n",
       "      <td>1.893682</td>\n",
       "      <td>0.499048</td>\n",
       "      <td>-0.054548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092448</td>\n",
       "      <td>-0.028477</td>\n",
       "      <td>0.022122</td>\n",
       "      <td>-0.128856</td>\n",
       "      <td>-0.021794</td>\n",
       "      <td>-0.076085</td>\n",
       "      <td>-0.225597</td>\n",
       "      <td>-0.058589</td>\n",
       "      <td>-0.082113</td>\n",
       "      <td>0.031275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019.854515</td>\n",
       "      <td>102.077282</td>\n",
       "      <td>-23.777190</td>\n",
       "      <td>0.144380</td>\n",
       "      <td>-0.382718</td>\n",
       "      <td>-0.156707</td>\n",
       "      <td>-0.436914</td>\n",
       "      <td>-0.252668</td>\n",
       "      <td>-0.306026</td>\n",
       "      <td>-0.231057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001019</td>\n",
       "      <td>-0.013980</td>\n",
       "      <td>0.286429</td>\n",
       "      <td>-0.059622</td>\n",
       "      <td>0.214921</td>\n",
       "      <td>-0.148949</td>\n",
       "      <td>-0.105750</td>\n",
       "      <td>0.063707</td>\n",
       "      <td>-0.066413</td>\n",
       "      <td>0.153625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-93.047269</td>\n",
       "      <td>3.008532</td>\n",
       "      <td>-1.043626</td>\n",
       "      <td>-1.761758</td>\n",
       "      <td>0.806475</td>\n",
       "      <td>-0.363198</td>\n",
       "      <td>0.145956</td>\n",
       "      <td>1.253429</td>\n",
       "      <td>0.217177</td>\n",
       "      <td>-0.039102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142385</td>\n",
       "      <td>-0.036040</td>\n",
       "      <td>0.081791</td>\n",
       "      <td>0.181499</td>\n",
       "      <td>0.050229</td>\n",
       "      <td>-0.106558</td>\n",
       "      <td>-0.127636</td>\n",
       "      <td>-0.115755</td>\n",
       "      <td>0.007704</td>\n",
       "      <td>-0.075429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-93.047352</td>\n",
       "      <td>3.008512</td>\n",
       "      <td>-1.044157</td>\n",
       "      <td>-1.618446</td>\n",
       "      <td>0.828785</td>\n",
       "      <td>-0.315290</td>\n",
       "      <td>-0.025347</td>\n",
       "      <td>1.236253</td>\n",
       "      <td>0.214051</td>\n",
       "      <td>-0.032500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013992</td>\n",
       "      <td>0.102745</td>\n",
       "      <td>0.034350</td>\n",
       "      <td>-0.116172</td>\n",
       "      <td>0.031205</td>\n",
       "      <td>0.043346</td>\n",
       "      <td>0.024315</td>\n",
       "      <td>0.268278</td>\n",
       "      <td>0.122683</td>\n",
       "      <td>0.009624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-232.290285</td>\n",
       "      <td>0.835958</td>\n",
       "      <td>-0.049379</td>\n",
       "      <td>-1.694110</td>\n",
       "      <td>0.530321</td>\n",
       "      <td>-0.234030</td>\n",
       "      <td>0.456226</td>\n",
       "      <td>-1.350935</td>\n",
       "      <td>-1.315274</td>\n",
       "      <td>-0.169406</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.126191</td>\n",
       "      <td>0.124354</td>\n",
       "      <td>0.023417</td>\n",
       "      <td>-0.017074</td>\n",
       "      <td>-0.102551</td>\n",
       "      <td>0.125890</td>\n",
       "      <td>-0.018602</td>\n",
       "      <td>-0.060292</td>\n",
       "      <td>-0.079793</td>\n",
       "      <td>-0.153269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1          2         3         4         5         6    \\\n",
       "0   742.633046  -74.001388  -0.568021 -1.238880  0.584801 -0.142957 -0.203460   \n",
       "1  2019.854515  102.077282 -23.777190  0.144380 -0.382718 -0.156707 -0.436914   \n",
       "2   -93.047269    3.008532  -1.043626 -1.761758  0.806475 -0.363198  0.145956   \n",
       "3   -93.047352    3.008512  -1.044157 -1.618446  0.828785 -0.315290 -0.025347   \n",
       "4  -232.290285    0.835958  -0.049379 -1.694110  0.530321 -0.234030  0.456226   \n",
       "\n",
       "        7         8         9      ...          91        92        93   \\\n",
       "0  1.893682  0.499048 -0.054548    ...    -0.092448 -0.028477  0.022122   \n",
       "1 -0.252668 -0.306026 -0.231057    ...    -0.001019 -0.013980  0.286429   \n",
       "2  1.253429  0.217177 -0.039102    ...     0.142385 -0.036040  0.081791   \n",
       "3  1.236253  0.214051 -0.032500    ...     0.013992  0.102745  0.034350   \n",
       "4 -1.350935 -1.315274 -0.169406    ...    -0.126191  0.124354  0.023417   \n",
       "\n",
       "        94        95        96        97        98        99        100  \n",
       "0 -0.128856 -0.021794 -0.076085 -0.225597 -0.058589 -0.082113  0.031275  \n",
       "1 -0.059622  0.214921 -0.148949 -0.105750  0.063707 -0.066413  0.153625  \n",
       "2  0.181499  0.050229 -0.106558 -0.127636 -0.115755  0.007704 -0.075429  \n",
       "3 -0.116172  0.031205  0.043346  0.024315  0.268278  0.122683  0.009624  \n",
       "4 -0.017074 -0.102551  0.125890 -0.018602 -0.060292 -0.079793 -0.153269  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principalDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = principalDf.iloc[0:4140]\n",
    "test_features = principalDf.iloc[4140:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_label.rename(columns={0: \"target\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDf = pd.concat([train_features, train_label], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>742.633046</td>\n",
       "      <td>-74.001388</td>\n",
       "      <td>-0.568021</td>\n",
       "      <td>-1.238880</td>\n",
       "      <td>0.584801</td>\n",
       "      <td>-0.142957</td>\n",
       "      <td>-0.203460</td>\n",
       "      <td>1.893682</td>\n",
       "      <td>0.499048</td>\n",
       "      <td>-0.054548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028477</td>\n",
       "      <td>0.022122</td>\n",
       "      <td>-0.128856</td>\n",
       "      <td>-0.021794</td>\n",
       "      <td>-0.076085</td>\n",
       "      <td>-0.225597</td>\n",
       "      <td>-0.058589</td>\n",
       "      <td>-0.082113</td>\n",
       "      <td>0.031275</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019.854515</td>\n",
       "      <td>102.077282</td>\n",
       "      <td>-23.777190</td>\n",
       "      <td>0.144380</td>\n",
       "      <td>-0.382718</td>\n",
       "      <td>-0.156707</td>\n",
       "      <td>-0.436914</td>\n",
       "      <td>-0.252668</td>\n",
       "      <td>-0.306026</td>\n",
       "      <td>-0.231057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013980</td>\n",
       "      <td>0.286429</td>\n",
       "      <td>-0.059622</td>\n",
       "      <td>0.214921</td>\n",
       "      <td>-0.148949</td>\n",
       "      <td>-0.105750</td>\n",
       "      <td>0.063707</td>\n",
       "      <td>-0.066413</td>\n",
       "      <td>0.153625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-93.047269</td>\n",
       "      <td>3.008532</td>\n",
       "      <td>-1.043626</td>\n",
       "      <td>-1.761758</td>\n",
       "      <td>0.806475</td>\n",
       "      <td>-0.363198</td>\n",
       "      <td>0.145956</td>\n",
       "      <td>1.253429</td>\n",
       "      <td>0.217177</td>\n",
       "      <td>-0.039102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036040</td>\n",
       "      <td>0.081791</td>\n",
       "      <td>0.181499</td>\n",
       "      <td>0.050229</td>\n",
       "      <td>-0.106558</td>\n",
       "      <td>-0.127636</td>\n",
       "      <td>-0.115755</td>\n",
       "      <td>0.007704</td>\n",
       "      <td>-0.075429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-93.047352</td>\n",
       "      <td>3.008512</td>\n",
       "      <td>-1.044157</td>\n",
       "      <td>-1.618446</td>\n",
       "      <td>0.828785</td>\n",
       "      <td>-0.315290</td>\n",
       "      <td>-0.025347</td>\n",
       "      <td>1.236253</td>\n",
       "      <td>0.214051</td>\n",
       "      <td>-0.032500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102745</td>\n",
       "      <td>0.034350</td>\n",
       "      <td>-0.116172</td>\n",
       "      <td>0.031205</td>\n",
       "      <td>0.043346</td>\n",
       "      <td>0.024315</td>\n",
       "      <td>0.268278</td>\n",
       "      <td>0.122683</td>\n",
       "      <td>0.009624</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-232.290285</td>\n",
       "      <td>0.835958</td>\n",
       "      <td>-0.049379</td>\n",
       "      <td>-1.694110</td>\n",
       "      <td>0.530321</td>\n",
       "      <td>-0.234030</td>\n",
       "      <td>0.456226</td>\n",
       "      <td>-1.350935</td>\n",
       "      <td>-1.315274</td>\n",
       "      <td>-0.169406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124354</td>\n",
       "      <td>0.023417</td>\n",
       "      <td>-0.017074</td>\n",
       "      <td>-0.102551</td>\n",
       "      <td>0.125890</td>\n",
       "      <td>-0.018602</td>\n",
       "      <td>-0.060292</td>\n",
       "      <td>-0.079793</td>\n",
       "      <td>-0.153269</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0           1          2         3         4         5         6  \\\n",
       "0   742.633046  -74.001388  -0.568021 -1.238880  0.584801 -0.142957 -0.203460   \n",
       "1  2019.854515  102.077282 -23.777190  0.144380 -0.382718 -0.156707 -0.436914   \n",
       "2   -93.047269    3.008532  -1.043626 -1.761758  0.806475 -0.363198  0.145956   \n",
       "3   -93.047352    3.008512  -1.044157 -1.618446  0.828785 -0.315290 -0.025347   \n",
       "4  -232.290285    0.835958  -0.049379 -1.694110  0.530321 -0.234030  0.456226   \n",
       "\n",
       "          7         8         9   ...          92        93        94  \\\n",
       "0  1.893682  0.499048 -0.054548   ...   -0.028477  0.022122 -0.128856   \n",
       "1 -0.252668 -0.306026 -0.231057   ...   -0.013980  0.286429 -0.059622   \n",
       "2  1.253429  0.217177 -0.039102   ...   -0.036040  0.081791  0.181499   \n",
       "3  1.236253  0.214051 -0.032500   ...    0.102745  0.034350 -0.116172   \n",
       "4 -1.350935 -1.315274 -0.169406   ...    0.124354  0.023417 -0.017074   \n",
       "\n",
       "         95        96        97        98        99       100  target  \n",
       "0 -0.021794 -0.076085 -0.225597 -0.058589 -0.082113  0.031275       1  \n",
       "1  0.214921 -0.148949 -0.105750  0.063707 -0.066413  0.153625       1  \n",
       "2  0.050229 -0.106558 -0.127636 -0.115755  0.007704 -0.075429       1  \n",
       "3  0.031205  0.043346  0.024315  0.268278  0.122683  0.009624       1  \n",
       "4 -0.102551  0.125890 -0.018602 -0.060292 -0.079793 -0.153269       1  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suhaniladani/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(train_features, train_label)\n",
    "target_pred = clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7331887201735358"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_label, target_pred, normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suhaniladani/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:436: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/suhaniladani/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2 = LogisticRegression(penalty='l2')\n",
    "lr2.fit(train_feature, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr2.predict(test_feature)\n",
    "y_pred = pd.DataFrame(data = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0    0.921909\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", np.mean(test_label == y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suhaniladani/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:436: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/suhaniladani/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l1', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1 = LogisticRegression(penalty='l1')\n",
    "lr1.fit(train_feature, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = lr1.predict(test_feature)\n",
    "y_pred1 = pd.DataFrame(data = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0    0.921909\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", np.mean(test_label == y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr = Ridge()\n",
    "rr.fit(train_feature, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score=rr.score(train_feature, train_label)\n",
    "test_score=rr.score(test_feature, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression train score: 0.6595275430398566\n",
      "Ridge regression test score: 0.4606932458484976\n"
     ]
    }
   ],
   "source": [
    "print(\"Ridge regression train score:\", train_score)\n",
    "print(\"Ridge regression test score:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "lasso.fit(train_feature, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score1 = lasso.score(train_feature, train_label)\n",
    "test_score1 = lasso.score(test_feature, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso regression train score: 0.07125684014404021\n",
      "Lasso regression test score: 0.09805881459719756\n"
     ]
    }
   ],
   "source": [
    "print(\"Lasso regression train score:\", train_score1)\n",
    "print(\"Lasso regression test score:\", test_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
