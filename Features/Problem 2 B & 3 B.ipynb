{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = pd.read_csv(\"spam_polluted/train_feature.txt\", delim_whitespace=True, header=None) \n",
    "test_feature = pd.read_csv(\"spam_polluted/test_feature.txt\", delim_whitespace=True, header=None) \n",
    "train_label = pd.read_csv(\"spam_polluted/train_label.txt\", delim_whitespace=True, header=None) \n",
    "test_label = pd.read_csv(\"spam_polluted/test_label.txt\", delim_whitespace=True, header=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WholeDf = pd.concat([train_feature, test_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1047</th>\n",
       "      <th>1048</th>\n",
       "      <th>1049</th>\n",
       "      <th>1050</th>\n",
       "      <th>1051</th>\n",
       "      <th>1052</th>\n",
       "      <th>1053</th>\n",
       "      <th>1054</th>\n",
       "      <th>1055</th>\n",
       "      <th>1056</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041051</td>\n",
       "      <td>0.068515</td>\n",
       "      <td>0.014376</td>\n",
       "      <td>0.068351</td>\n",
       "      <td>0.032469</td>\n",
       "      <td>0.014087</td>\n",
       "      <td>0.034152</td>\n",
       "      <td>0.051189</td>\n",
       "      <td>0.063388</td>\n",
       "      <td>0.043658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062413</td>\n",
       "      <td>0.050598</td>\n",
       "      <td>0.071449</td>\n",
       "      <td>0.034827</td>\n",
       "      <td>0.037157</td>\n",
       "      <td>0.051147</td>\n",
       "      <td>0.067859</td>\n",
       "      <td>0.052220</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.009583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019171</td>\n",
       "      <td>0.045824</td>\n",
       "      <td>0.011757</td>\n",
       "      <td>0.031530</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>0.073789</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>0.072750</td>\n",
       "      <td>0.040348</td>\n",
       "      <td>0.029986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010594</td>\n",
       "      <td>0.013711</td>\n",
       "      <td>0.054859</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>0.053976</td>\n",
       "      <td>0.029885</td>\n",
       "      <td>0.063413</td>\n",
       "      <td>0.070903</td>\n",
       "      <td>0.026120</td>\n",
       "      <td>0.008427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055207</td>\n",
       "      <td>0.071441</td>\n",
       "      <td>0.058734</td>\n",
       "      <td>0.058241</td>\n",
       "      <td>0.034914</td>\n",
       "      <td>0.018111</td>\n",
       "      <td>0.019574</td>\n",
       "      <td>0.009803</td>\n",
       "      <td>0.065727</td>\n",
       "      <td>0.058667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1057 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9       ...     \\\n",
       "0  0.21  0.28  0.50   0.0  0.14  0.28  0.21  0.07  0.00  0.94    ...      \n",
       "1  0.06  0.00  0.71   0.0  1.23  0.19  0.19  0.12  0.64  0.25    ...      \n",
       "2  0.00  0.00  0.00   0.0  0.63  0.00  0.31  0.63  0.31  0.63    ...      \n",
       "3  0.00  0.00  0.00   0.0  0.63  0.00  0.31  0.63  0.31  0.63    ...      \n",
       "4  0.00  0.00  0.00   0.0  1.85  0.00  0.00  1.85  0.00  0.00    ...      \n",
       "\n",
       "       1047      1048      1049      1050      1051      1052      1053  \\\n",
       "0  0.041051  0.068515  0.014376  0.068351  0.032469  0.014087  0.034152   \n",
       "1  0.062413  0.050598  0.071449  0.034827  0.037157  0.051147  0.067859   \n",
       "2  0.019171  0.045824  0.011757  0.031530  0.032750  0.073789  0.045900   \n",
       "3  0.010594  0.013711  0.054859  0.004493  0.053976  0.029885  0.063413   \n",
       "4  0.055207  0.071441  0.058734  0.058241  0.034914  0.018111  0.019574   \n",
       "\n",
       "       1054      1055      1056  \n",
       "0  0.051189  0.063388  0.043658  \n",
       "1  0.052220  0.004742  0.009583  \n",
       "2  0.072750  0.040348  0.029986  \n",
       "3  0.070903  0.026120  0.008427  \n",
       "4  0.009803  0.065727  0.058667  \n",
       "\n",
       "[5 rows x 1057 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WholeDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalComponents = pca.fit_transform(WholeDf)\n",
    "principalDf = pd.DataFrame(data = principalComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>742.633046</td>\n",
       "      <td>-74.001388</td>\n",
       "      <td>-0.568021</td>\n",
       "      <td>-1.238880</td>\n",
       "      <td>0.584801</td>\n",
       "      <td>-0.142957</td>\n",
       "      <td>-0.203460</td>\n",
       "      <td>1.893682</td>\n",
       "      <td>0.499048</td>\n",
       "      <td>-0.054548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140692</td>\n",
       "      <td>-0.002343</td>\n",
       "      <td>0.014136</td>\n",
       "      <td>0.068103</td>\n",
       "      <td>0.198768</td>\n",
       "      <td>0.157938</td>\n",
       "      <td>0.158921</td>\n",
       "      <td>0.100313</td>\n",
       "      <td>-0.128511</td>\n",
       "      <td>-0.144393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019.854515</td>\n",
       "      <td>102.077282</td>\n",
       "      <td>-23.777190</td>\n",
       "      <td>0.144380</td>\n",
       "      <td>-0.382718</td>\n",
       "      <td>-0.156707</td>\n",
       "      <td>-0.436914</td>\n",
       "      <td>-0.252668</td>\n",
       "      <td>-0.306026</td>\n",
       "      <td>-0.231057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028509</td>\n",
       "      <td>-0.115721</td>\n",
       "      <td>0.204547</td>\n",
       "      <td>0.060516</td>\n",
       "      <td>-0.139693</td>\n",
       "      <td>-0.146518</td>\n",
       "      <td>0.064716</td>\n",
       "      <td>0.063561</td>\n",
       "      <td>-0.179876</td>\n",
       "      <td>-0.003150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-93.047269</td>\n",
       "      <td>3.008532</td>\n",
       "      <td>-1.043626</td>\n",
       "      <td>-1.761758</td>\n",
       "      <td>0.806475</td>\n",
       "      <td>-0.363198</td>\n",
       "      <td>0.145956</td>\n",
       "      <td>1.253429</td>\n",
       "      <td>0.217177</td>\n",
       "      <td>-0.039102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208021</td>\n",
       "      <td>-0.148798</td>\n",
       "      <td>-0.268612</td>\n",
       "      <td>-0.024923</td>\n",
       "      <td>-0.061067</td>\n",
       "      <td>-0.095469</td>\n",
       "      <td>-0.048580</td>\n",
       "      <td>0.003587</td>\n",
       "      <td>0.010607</td>\n",
       "      <td>0.027843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-93.047352</td>\n",
       "      <td>3.008512</td>\n",
       "      <td>-1.044157</td>\n",
       "      <td>-1.618446</td>\n",
       "      <td>0.828785</td>\n",
       "      <td>-0.315290</td>\n",
       "      <td>-0.025347</td>\n",
       "      <td>1.236253</td>\n",
       "      <td>0.214051</td>\n",
       "      <td>-0.032500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055937</td>\n",
       "      <td>-0.036837</td>\n",
       "      <td>0.159415</td>\n",
       "      <td>-0.116205</td>\n",
       "      <td>0.020290</td>\n",
       "      <td>-0.022564</td>\n",
       "      <td>0.051349</td>\n",
       "      <td>0.250279</td>\n",
       "      <td>-0.079891</td>\n",
       "      <td>0.153495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-232.290285</td>\n",
       "      <td>0.835958</td>\n",
       "      <td>-0.049379</td>\n",
       "      <td>-1.694110</td>\n",
       "      <td>0.530321</td>\n",
       "      <td>-0.234030</td>\n",
       "      <td>0.456226</td>\n",
       "      <td>-1.350935</td>\n",
       "      <td>-1.315274</td>\n",
       "      <td>-0.169406</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115334</td>\n",
       "      <td>0.197399</td>\n",
       "      <td>0.084158</td>\n",
       "      <td>0.044184</td>\n",
       "      <td>-0.040044</td>\n",
       "      <td>-0.051056</td>\n",
       "      <td>0.347282</td>\n",
       "      <td>-0.015360</td>\n",
       "      <td>0.131867</td>\n",
       "      <td>-0.023268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1          2         3         4         5         6    \\\n",
       "0   742.633046  -74.001388  -0.568021 -1.238880  0.584801 -0.142957 -0.203460   \n",
       "1  2019.854515  102.077282 -23.777190  0.144380 -0.382718 -0.156707 -0.436914   \n",
       "2   -93.047269    3.008532  -1.043626 -1.761758  0.806475 -0.363198  0.145956   \n",
       "3   -93.047352    3.008512  -1.044157 -1.618446  0.828785 -0.315290 -0.025347   \n",
       "4  -232.290285    0.835958  -0.049379 -1.694110  0.530321 -0.234030  0.456226   \n",
       "\n",
       "        7         8         9      ...          91        92        93   \\\n",
       "0  1.893682  0.499048 -0.054548    ...     0.140692 -0.002343  0.014136   \n",
       "1 -0.252668 -0.306026 -0.231057    ...    -0.028509 -0.115721  0.204547   \n",
       "2  1.253429  0.217177 -0.039102    ...    -0.208021 -0.148798 -0.268612   \n",
       "3  1.236253  0.214051 -0.032500    ...     0.055937 -0.036837  0.159415   \n",
       "4 -1.350935 -1.315274 -0.169406    ...    -0.115334  0.197399  0.084158   \n",
       "\n",
       "        94        95        96        97        98        99        100  \n",
       "0  0.068103  0.198768  0.157938  0.158921  0.100313 -0.128511 -0.144393  \n",
       "1  0.060516 -0.139693 -0.146518  0.064716  0.063561 -0.179876 -0.003150  \n",
       "2 -0.024923 -0.061067 -0.095469 -0.048580  0.003587  0.010607  0.027843  \n",
       "3 -0.116205  0.020290 -0.022564  0.051349  0.250279 -0.079891  0.153495  \n",
       "4  0.044184 -0.040044 -0.051056  0.347282 -0.015360  0.131867 -0.023268  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principalDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = principalDf.iloc[0:4140]\n",
    "test_features = principalDf.iloc[4140:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_label.rename(columns={0: \"target\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDf = pd.concat([train_features, train_label], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>742.633046</td>\n",
       "      <td>-74.001388</td>\n",
       "      <td>-0.568021</td>\n",
       "      <td>-1.238880</td>\n",
       "      <td>0.584801</td>\n",
       "      <td>-0.142957</td>\n",
       "      <td>-0.203460</td>\n",
       "      <td>1.893682</td>\n",
       "      <td>0.499048</td>\n",
       "      <td>-0.054548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002343</td>\n",
       "      <td>0.014136</td>\n",
       "      <td>0.068103</td>\n",
       "      <td>0.198768</td>\n",
       "      <td>0.157938</td>\n",
       "      <td>0.158921</td>\n",
       "      <td>0.100313</td>\n",
       "      <td>-0.128511</td>\n",
       "      <td>-0.144393</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019.854515</td>\n",
       "      <td>102.077282</td>\n",
       "      <td>-23.777190</td>\n",
       "      <td>0.144380</td>\n",
       "      <td>-0.382718</td>\n",
       "      <td>-0.156707</td>\n",
       "      <td>-0.436914</td>\n",
       "      <td>-0.252668</td>\n",
       "      <td>-0.306026</td>\n",
       "      <td>-0.231057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115721</td>\n",
       "      <td>0.204547</td>\n",
       "      <td>0.060516</td>\n",
       "      <td>-0.139693</td>\n",
       "      <td>-0.146518</td>\n",
       "      <td>0.064716</td>\n",
       "      <td>0.063561</td>\n",
       "      <td>-0.179876</td>\n",
       "      <td>-0.003150</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-93.047269</td>\n",
       "      <td>3.008532</td>\n",
       "      <td>-1.043626</td>\n",
       "      <td>-1.761758</td>\n",
       "      <td>0.806475</td>\n",
       "      <td>-0.363198</td>\n",
       "      <td>0.145956</td>\n",
       "      <td>1.253429</td>\n",
       "      <td>0.217177</td>\n",
       "      <td>-0.039102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.148798</td>\n",
       "      <td>-0.268612</td>\n",
       "      <td>-0.024923</td>\n",
       "      <td>-0.061067</td>\n",
       "      <td>-0.095469</td>\n",
       "      <td>-0.048580</td>\n",
       "      <td>0.003587</td>\n",
       "      <td>0.010607</td>\n",
       "      <td>0.027843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-93.047352</td>\n",
       "      <td>3.008512</td>\n",
       "      <td>-1.044157</td>\n",
       "      <td>-1.618446</td>\n",
       "      <td>0.828785</td>\n",
       "      <td>-0.315290</td>\n",
       "      <td>-0.025347</td>\n",
       "      <td>1.236253</td>\n",
       "      <td>0.214051</td>\n",
       "      <td>-0.032500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036837</td>\n",
       "      <td>0.159415</td>\n",
       "      <td>-0.116205</td>\n",
       "      <td>0.020290</td>\n",
       "      <td>-0.022564</td>\n",
       "      <td>0.051349</td>\n",
       "      <td>0.250279</td>\n",
       "      <td>-0.079891</td>\n",
       "      <td>0.153495</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-232.290285</td>\n",
       "      <td>0.835958</td>\n",
       "      <td>-0.049379</td>\n",
       "      <td>-1.694110</td>\n",
       "      <td>0.530321</td>\n",
       "      <td>-0.234030</td>\n",
       "      <td>0.456226</td>\n",
       "      <td>-1.350935</td>\n",
       "      <td>-1.315274</td>\n",
       "      <td>-0.169406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197399</td>\n",
       "      <td>0.084158</td>\n",
       "      <td>0.044184</td>\n",
       "      <td>-0.040044</td>\n",
       "      <td>-0.051056</td>\n",
       "      <td>0.347282</td>\n",
       "      <td>-0.015360</td>\n",
       "      <td>0.131867</td>\n",
       "      <td>-0.023268</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0           1          2         3         4         5         6  \\\n",
       "0   742.633046  -74.001388  -0.568021 -1.238880  0.584801 -0.142957 -0.203460   \n",
       "1  2019.854515  102.077282 -23.777190  0.144380 -0.382718 -0.156707 -0.436914   \n",
       "2   -93.047269    3.008532  -1.043626 -1.761758  0.806475 -0.363198  0.145956   \n",
       "3   -93.047352    3.008512  -1.044157 -1.618446  0.828785 -0.315290 -0.025347   \n",
       "4  -232.290285    0.835958  -0.049379 -1.694110  0.530321 -0.234030  0.456226   \n",
       "\n",
       "          7         8         9   ...          92        93        94  \\\n",
       "0  1.893682  0.499048 -0.054548   ...   -0.002343  0.014136  0.068103   \n",
       "1 -0.252668 -0.306026 -0.231057   ...   -0.115721  0.204547  0.060516   \n",
       "2  1.253429  0.217177 -0.039102   ...   -0.148798 -0.268612 -0.024923   \n",
       "3  1.236253  0.214051 -0.032500   ...   -0.036837  0.159415 -0.116205   \n",
       "4 -1.350935 -1.315274 -0.169406   ...    0.197399  0.084158  0.044184   \n",
       "\n",
       "         95        96        97        98        99       100  target  \n",
       "0  0.198768  0.157938  0.158921  0.100313 -0.128511 -0.144393       1  \n",
       "1 -0.139693 -0.146518  0.064716  0.063561 -0.179876 -0.003150       1  \n",
       "2 -0.061067 -0.095469 -0.048580  0.003587  0.010607  0.027843       1  \n",
       "3  0.020290 -0.022564  0.051349  0.250279 -0.079891  0.153495       1  \n",
       "4 -0.040044 -0.051056  0.347282 -0.015360  0.131867 -0.023268       1  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suhaniladani/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(train_features, train_label)\n",
    "target_pred = clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7331887201735358"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_label, target_pred, normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suhaniladani/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:436: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/suhaniladani/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2 = LogisticRegression(penalty='l2')\n",
    "lr2.fit(train_feature, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr2.predict(test_feature)\n",
    "y_pred = pd.DataFrame(data = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0    0.921909\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", np.mean(test_label == y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suhaniladani/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:436: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/suhaniladani/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l1', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1 = LogisticRegression(penalty='l1')\n",
    "lr1.fit(train_feature, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = lr1.predict(test_feature)\n",
    "y_pred1 = pd.DataFrame(data = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0    0.921909\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", np.mean(test_label == y_pred1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
